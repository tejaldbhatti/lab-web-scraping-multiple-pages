{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://en.wikipedia.org/wiki/Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. download html with a get request\n",
    "response = requests.get(url)\n",
    "response.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.select(\"#mw-content-text > div.mw-content-ltr.mw-parser-output > h2:nth-child(6) > span.mw-editsection > a\")\n",
    "# soup.select(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.select(\"a\")\n",
    "links_list = [] # this will give the list of all the links\n",
    "for i in links:\n",
    "    href = i.get('href')\n",
    "    if href and href.startswith('/wiki/'):  # Filter out only Wikipedia internal links\n",
    "        links_list.append(href)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = links_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the number of titles that have changed in the United States Code since its last release point: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'http://uscode.house.gov/download/download.shtml'\n",
    "response2 = requests.get(url2)\n",
    "response2.status_code # 200 status code means OK!\n",
    "soup2 = BeautifulSoup(response2.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of titles that have changed in the United States Code since its last release point:  ['Title 2 - The Congress', 'Title 5 - Government Organization and Employees ٭', 'Title 6 - Domestic Security', 'Title 18 - Crimes and Criminal Procedure ٭', 'Title 19 - Customs Duties', 'Title 42 - The Public Health and Welfare']\n"
     ]
    }
   ],
   "source": [
    "list_chnged = soup2.select(\"div.usctitlechanged\") \n",
    "new_list=[]\n",
    "for i in range(0,len(list_chnged)):\n",
    "    new_list.append(list_chnged[i].get_text().strip())\n",
    "print(\"number of titles that have changed in the United States Code since its last release point: \",new_list)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Python list with the top ten FBI's Most Wanted names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = 'https://www.fbi.gov/wanted/topten'\n",
    "response3 = requests.get(url3)\n",
    "response3.status_code # 200 status code means OK!\n",
    "soup3 = BeautifulSoup(response3.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = soup3.find_all('h3', {\"class\":\"title\"})\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(soup3) # here <div class=\"error_page\"> not allowed to access the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = 'https://www.emsc-csem.org/Earthquake/'\n",
    "response4 = requests.get(url4)\n",
    "response4.status_code # 200 status code means OK!\n",
    "soup4 = BeautifulSoup(response4.content, \"html.parser\")\n",
    "#print(soup4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = soup4.find_all('td', {\"class\":\"tblat\"})\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all language names and number of related articles in the order they appear in wikipedia.org: url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = 'https://www.wikipedia.org/'\n",
    "response5 = requests.get(url5)\n",
    "response5.status_code # 200 status code means OK!\n",
    "soup5 = BeautifulSoup(response5.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup5.select(\"#www-wikipedia-org > main > nav.central-featured > div.central-featured-lang.lang5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "langu_list = soup5.select(\"div.central-featured-lang\") \n",
    "lang_list=[]\n",
    "for i in range(0,len(langu_list)):\n",
    "    lang_list.append(langu_list[i].get_text().strip())\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lang = []\n",
    "article =[]\n",
    "for i in range(0,len(lang_list)):\n",
    "    name_lang.append(lang_list[i].split(\"\\n\")[0])\n",
    "    article.append((lang_list[i].split(\"\\n\")[1]).split(\"+\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>6,782,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Русский</td>\n",
       "      <td>1 963 000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本語</td>\n",
       "      <td>1,403,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Español</td>\n",
       "      <td>1.930.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2.881.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Français</td>\n",
       "      <td>2 590 000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italiano</td>\n",
       "      <td>1.847.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中文</td>\n",
       "      <td>1,403,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>فارسی</td>\n",
       "      <td>۹۹۳٬۰۰۰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>العربية</td>\n",
       "      <td>١٬٢٢٧٬٠٠٠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language    Article\n",
       "0   English  6,782,000\n",
       "1   Русский  1 963 000\n",
       "2       日本語  1,403,000\n",
       "3   Español  1.930.000\n",
       "4   Deutsch  2.881.000\n",
       "5  Français  2 590 000\n",
       "6  Italiano  1.847.000\n",
       "7        中文  1,403,000\n",
       "8     فارسی    ۹۹۳٬۰۰۰\n",
       "9   العربية  ١٬٢٢٧٬٠٠٠"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"Language\":name_lang,\"Article\":article})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "url6 = 'https://data.gov.uk/'\n",
    "response6 = requests.get(url6)\n",
    "response6.status_code # 200 status code means OK!\n",
    "soup6 = BeautifulSoup(response6.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup6.select(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = soup6.select(\"a\")\n",
    "links_data = [] # this will give the list of all the links\n",
    "for i in dataset_list:\n",
    "    href = i.get('href')\n",
    "    if href and href.startswith('/search?filters'):  # Filter out only Wikipedia internal links\n",
    "        links_data.append(i.get_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "url7 = url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "response7 = requests.get(url7)\n",
    "response7.status_code # 200 status code means OK!\n",
    "soup7 = BeautifulSoup(response7.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup7.select(\"a\")\n",
    "table = soup7.find('table',{\"class\":\"wikitable sortable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_all(\"tr\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = []\n",
    "native_speakers =[]\n",
    "for i in range(0,len(rows)):\n",
    "    columns = rows[i].find_all(\"td\")\n",
    "    language = columns[1].text.strip()\n",
    "    speaker = columns[2].text.strip().replace(\",\",\"\")\n",
    "    languages.append(language)\n",
    "    native_speakers.append(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Language\":languages,\"Native_Speaker\":native_speakers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Native_Speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>12.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>6.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>3.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>3.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>3.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Russian</td>\n",
       "      <td>2.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Western Punjabi</td>\n",
       "      <td>1.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Javanese</td>\n",
       "      <td>1.1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Language Native_Speaker\n",
       "0   Mandarin Chinese          12.3%\n",
       "1            Spanish           6.0%\n",
       "2            English           5.1%\n",
       "3             Arabic           5.1%\n",
       "4              Hindi           3.5%\n",
       "5            Bengali           3.3%\n",
       "6         Portuguese           3.0%\n",
       "7            Russian           2.1%\n",
       "8           Japanese           1.7%\n",
       "9    Western Punjabi           1.3%\n",
       "10          Javanese           1.1%"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
